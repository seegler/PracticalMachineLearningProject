---
title: "Practical Machine Learning - Project 1"
author: "Seegler"
date: "06/21/2015"
output: html_document
---
##Synopsis  

Goal of this project is to analyze the personal movement data and apply machine learning algorithms to build a model to predict the the manner in which participants perform the exercise( Classe outcome variable).  Project evaluates the out of sample error to assess the performance of the model. Finally, project predicts the outcomes for the given 20 test cases and saves the results in text files for submission.

Project uses following data sets:  
Training - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv  
Testing - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

##Load Training Data

```{r, cache=TRUE}

temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", temp, method = "curl")
train_data <- read.csv(temp, na.strings = c("NA", "#DIV/0!"))
unlink(temp)
```

##Preprocessing and Exploratory Analysis

Inspect class variable values
```{r}
dim(train_data)
table(train_data$classe)
```

Training data has 19622 observations and 160 variables. Classe variable has 5 factors-A,B,C,D,E.

###Partition given training data for cross validation

Split given trining data into 70:30 for model fitting and corss validation respectively.

```{r}
library(caret)

set.seed(12345)
trainset <- createDataPartition(train_data$classe, p = 0.7, list = FALSE)
Training <- train_data[trainset, ]
CrossValSet <- train_data[-trainset, ]
```

###Cleanup data

Exclude variables that are either near zero variance, having more than 90% missing values or the description columns

```{r}

nearZeroVarCols <- nearZeroVar(Training)
Training <- Training[, -nearZeroVarCols]

descriptionCols <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",  "cvtd_timestamp", "new_window", "num_window")
Training <- Training[, !names(Training) %in% descriptionCols]

NAsPerColumn<- apply(Training,2,function(x) {sum(is.na(x))});
Training <- Training[,which(NAsPerColumn <  nrow(Training)*0.9)]; 

```
##Build the Model

Build a Random Forest model. We could try other algorithms like Boosted Tree or Linear Discriminant Analysis. However Random Forest gives good accuracy at the cost of speed. Run randonForest with Classe variable as the outcome against all other variables as predictors.

```{r}

library(randomForest)
model <- randomForest(classe ~ ., data = Training, importance = TRUE, ntrees = 10)

```

##Cross Validation

Test the model accuracy against Training set and Cross Validation set

###Accuracy of predicting training set
```{r}
ptraining <- predict(model, Training)
print(confusionMatrix(ptraining, Training$classe))
```

Acuracy of prediction is 100% (95% CI : (0.9997, 1)) agaist the Training set which is used for fitting the model. This is excellent and expected. However accuracy against the cross validation set is more important.

###Accuracy of predicting cross validation set
```{r}
ptesting <- predict(model, CrossValSet)
print(confusionMatrix(ptesting, CrossValSet$classe))
```
Accuracy is 99.32% which means out of sample error is 0.68%. This is very high accuracy and shows our model performance is good.

##Submission
load submission test data
```{r cache=TRUE}
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", temp, method = "curl")
test_data <- read.csv(temp, na.strings = c("NA", "#DIV/0!"))
unlink(temp)
```
Based on the fitted model, predict the Classe variable outcome for the 20 test cases in submission test set.

```{r}
answers <- predict(model, test_data)
answers
```
Write the test case outcomes to 20 files for uploading

```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)
```